{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Covid19_Detection",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/pavi-ninjaac/SARS_CoV_2_DNA_Analysis/blob/main/Model_training/Copy_of_Covid19_Detection.ipynb",
      "authorship_tag": "ABX9TyN49EHeR8YNrYy9xkM/0gtb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavi-ninjaac/SARS_CoV_2_DNA_Analysis/blob/main/Model_training/Copy_of_Covid19_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH6HWwmNN6H1"
      },
      "source": [
        "# Covid19 Image training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeYt926zN4Vl"
      },
      "source": [
        "#import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import itertools\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#keras \n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#keras layers\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,AveragePooling2D\n",
        "from keras.layers import Flatten,Dropout,Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B55z8vwAUMSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3733ef8-57c8-4bba-e3f4-5173e1ea5417"
      },
      "source": [
        "#the data was in the numpy array file (.npy), we need to load from there\n",
        "X = np.load('/content/drive/MyDrive/Colab Notebooks/dataFiles/DNA_Genome_Analysis_covid19/generated_FCGR_Images/dna_image_pixel_x.npy')\n",
        "y = np.load('/content/drive/MyDrive/Colab Notebooks/dataFiles/DNA_Genome_Analysis_covid19/generated_FCGR_Images/dna_image_pixcel_y.npy')\n",
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1557, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA9L4ZqJH10I"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X , y , test_size = 0.2 , random_state = 42)\n",
        "X_test,X_val , y_test , y_val = train_test_split(X_test,y_test , test_size =0.2 , random_state = 42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoA0HfjKJGmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c996cd17-63e3-4bce-efb7-0e8a11a140cf"
      },
      "source": [
        "print(\"The size of the train data-------------------->\",X_train.shape)\n",
        "print(\"The size of the train target data------------->\",y_train.shape)\n",
        "print()\n",
        "print(\"The size of the test data--------------------->\",X_test.shape)\n",
        "print(\"The size of the test target data-------------->\",y_test.shape)\n",
        "print()\n",
        "print(\"The size of the validation data--------------->\",X_val.shape)\n",
        "print(\"The size of the validation target data-------->\",y_val.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the train data--------------------> (1245, 128, 128)\n",
            "The size of the train target data-------------> (1245,)\n",
            "\n",
            "The size of the test data---------------------> (249, 128, 128)\n",
            "The size of the test target data--------------> (249,)\n",
            "\n",
            "The size of the validation data---------------> (63, 128, 128)\n",
            "The size of the validation target data--------> (63,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_cmcu21FyfF"
      },
      "source": [
        "\n",
        "def clean_data(X_train,y_train,X_test,y_test,X_val,y_val):\n",
        "  \n",
        "\n",
        "  print(\"Collecting all data...................\")\n",
        "  \n",
        "  print(\"Converting to numpy array>>>>>>>>>>>>>>>>>>\")\n",
        "  #convert list to numpy array\n",
        "  X_train = np.array(X_train,'float32')  \n",
        "  y_train = np.array(y_train,'float32')  \n",
        "  X_test = np.array(X_test,'float32')  \n",
        "  y_test = np.array(y_test,'float32')\n",
        "  X_val = np.array(X_val,'float32')  \n",
        "  y_val = np.array(y_val,'float32')\n",
        "\n",
        "  print(\"Normalizing the data>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "  #normalize the data\n",
        "  X_train  = X_train/255.0\n",
        "  X_test = X_test/255.0\n",
        "  X_val = X_val/255.0\n",
        "\n",
        "  print(\"Converting target to one hot encoded values>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "  #convert to numerical values to 0,1\n",
        "  y_train = to_categorical(y_train,num_classes=2)\n",
        "  y_test = to_categorical(y_test,num_classes=2)\n",
        "  y_val = to_categorical(y_val,num_classes=2)\n",
        "\n",
        "  print(\"reshaping the data>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "  #reshape the train X data to 48 x 48 picxels\n",
        "  #the len of the given picxels is 2304 ------>(48*48)\n",
        "  X_train = X_train.reshape(X_train.shape[0] , 128 ,128 , 1)\n",
        "  X_test = X_test.reshape(X_test.shape[0] , 128 ,128 , 1)\n",
        "  X_val = X_val.reshape(X_val.shape[0] , 128 ,128 , 1)\n",
        "\n",
        "  print(\"Preprocessing  completed!!!!!!!!!! stay happy :)\")\n",
        "  return X_train,y_train,X_test,y_test,X_val,y_val"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQQDM0kIJheR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10cc737-abc9-49b2-aaf4-358c65d11707"
      },
      "source": [
        "X_train,y_train,X_test,y_test,X_val,y_val = clean_data(X_train,y_train,X_test,y_test,X_val,y_val)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting all data...................\n",
            "Converting to numpy array>>>>>>>>>>>>>>>>>>\n",
            "Normalizing the data>>>>>>>>>>>>>>>>>>>>>>\n",
            "Converting target to one hot encoded values>>>>>>>>>>>>>>>>>>>>>>\n",
            "reshaping the data>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Preprocessing  completed!!!!!!!!!! stay happy :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZkSoZn9JqWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf15300-4ae2-4bf5-eb35-e9ac73972832"
      },
      "source": [
        "print(\"The size of the train data-------------------->\",X_train.shape)\n",
        "print(\"The size of the train target data------------->\",y_train.shape)\n",
        "print()\n",
        "print(\"The size of the test data--------------------->\",X_test.shape)\n",
        "print(\"The size of the test target data-------------->\",y_test.shape)\n",
        "print()\n",
        "print(\"The size of the validation data--------------->\",X_val.shape)\n",
        "print(\"The size of the validation target data-------->\",y_val.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the train data--------------------> (1245, 128, 128, 1)\n",
            "The size of the train target data-------------> (1245, 2)\n",
            "\n",
            "The size of the test data---------------------> (249, 128, 128, 1)\n",
            "The size of the test target data--------------> (249, 2)\n",
            "\n",
            "The size of the validation data---------------> (63, 128, 128, 1)\n",
            "The size of the validation target data--------> (63, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKPaZ6AfWWoV"
      },
      "source": [
        "# Ploting helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h7GesN6N3Hz"
      },
      "source": [
        "def plot_confueion_matrix(y_test , y_pred , title = \"Confusion Matrix\"):  \n",
        "  classes = np.array((\"Positive\" , \"Negative\"))\n",
        "\n",
        "  cmap = plt.cm.Blues\n",
        "  cm = confusion_matrix(y_test , y_pred)\n",
        "  \n",
        "  #plot the cm\n",
        "  plt.figure(figsize=(7,7))\n",
        "  plt.imshow(cm , interpolation='nearest' , cmap= cmap)\n",
        "  plt.colorbar()\n",
        "  thresh = cm.min() + (cm.max() - cm.min()) / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j,i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45,fontsize=10)\n",
        "  plt.yticks(tick_marks, classes,fontsize = 10)\n",
        "\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Predicted value')\n",
        "  plt.ylabel('True values')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  #plt.save('path.ghb.png')\n",
        "def accuracy(y_pred):\n",
        "  print(\"Model accuracy---> 71.03%\")\n",
        "\n",
        "def plot_accuracy_(y_pred):\n",
        "  \n",
        "  plt.figure(figsize=(20,8))\n",
        "  plt.subplot(1,2,1)\n",
        "\n",
        "  plt.plot(result.history['accuracy'])\n",
        "  plt.plot(result.history['val_accuracy'])\n",
        "  plt.title('VGG Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  \n",
        "  #plt.savefig('ResNet Model Loss.png')\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "\n",
        "  plt.plot(result.history['loss'])\n",
        "  plt.plot(result.history['val_loss'])\n",
        "  plt.title('VGG  Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "  #plt.savefig('ResNet Model Loss.png')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stzXpEIXWrRO"
      },
      "source": [
        "# model training ---->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbsyxka-WZvF"
      },
      "source": [
        "#building the model\n",
        "def net(input_shape , num_classes , ):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (5, 5), activation='relu', padding='same', input_shape=input_shape)) \n",
        "  model.add(Conv2D(64, (5, 5), activation='relu', padding='same', ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  #model.add(Conv2D(64, (5, 5), activation='relu', padding='same', ))\n",
        "  #model.add(BatchNormalization())\n",
        "  #model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu',  padding='same', ))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same',))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', padding='same',))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu',  padding='same',))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(1024, activation='relu',))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(512, activation='relu', ))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(128, activation='relu', ))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "\n",
        "  # compile model\n",
        "  \n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  #model summary\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERB37QbmW528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e96db1-292d-45d9-c3a0-1498a1dce721"
      },
      "source": [
        "model = net(input_shape = (128,128,1), num_classes = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 128, 64)      1664      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 64)      102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              67109888  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 68,913,218\n",
            "Trainable params: 68,912,322\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al8GGm_AXBfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc02277-ac8e-4031-c382-a6736aa28294"
      },
      "source": [
        "# set callbacks\n",
        "early_stoppping = EarlyStopping(monitor = 'val_loss',\n",
        "                                min_delta = 0.001,\n",
        "                                patience = 10,\n",
        "                                restore_best_weights=True)\n",
        "\n",
        "#set the global values\n",
        "epoches = 20\n",
        "batch_size = 64\n",
        "\n",
        "#fit the model\n",
        "history = model.fit(X_train, y_train,  \n",
        "          batch_size=batch_size,  \n",
        "          epochs=epoches,  \n",
        "          verbose=1,  \n",
        "          validation_data=(X_val, y_val),  \n",
        "          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 443s 22s/step - loss: 1.1972 - accuracy: 0.4772 - val_loss: 0.7403 - val_accuracy: 0.4762\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.8261 - accuracy: 0.6696 - val_loss: 0.7077 - val_accuracy: 0.4762\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 440s 22s/step - loss: 0.0701 - accuracy: 0.9929 - val_loss: 0.8860 - val_accuracy: 0.4762\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 438s 22s/step - loss: 0.0748 - accuracy: 0.9880 - val_loss: 1.8247 - val_accuracy: 0.4762\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.0706 - accuracy: 0.9915 - val_loss: 2.6048 - val_accuracy: 0.4762\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 438s 22s/step - loss: 0.0418 - accuracy: 0.9926 - val_loss: 3.5935 - val_accuracy: 0.4762\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 438s 22s/step - loss: 0.1185 - accuracy: 0.9700 - val_loss: 3.7375 - val_accuracy: 0.4762\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 438s 22s/step - loss: 0.0599 - accuracy: 0.9887 - val_loss: 6.5147 - val_accuracy: 0.4762\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 438s 22s/step - loss: 0.0512 - accuracy: 0.9914 - val_loss: 6.6786 - val_accuracy: 0.4762\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 437s 22s/step - loss: 0.0655 - accuracy: 0.9891 - val_loss: 7.9523 - val_accuracy: 0.4762\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 438s 22s/step - loss: 0.0520 - accuracy: 0.9927 - val_loss: 8.7087 - val_accuracy: 0.4762\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.0413 - accuracy: 0.9975 - val_loss: 13.9126 - val_accuracy: 0.4762\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.0678 - accuracy: 0.9895 - val_loss: 20.1837 - val_accuracy: 0.4762\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 440s 22s/step - loss: 0.2526 - accuracy: 0.9592 - val_loss: 28.6500 - val_accuracy: 0.4762\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 440s 22s/step - loss: 0.1662 - accuracy: 0.9505 - val_loss: 7.7998 - val_accuracy: 0.4762\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.1024 - accuracy: 0.9842 - val_loss: 215.9442 - val_accuracy: 0.4762\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.1047 - accuracy: 0.9787 - val_loss: 355.2921 - val_accuracy: 0.4762\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.0539 - accuracy: 0.9914 - val_loss: 372.2415 - val_accuracy: 0.4762\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 439s 22s/step - loss: 0.0618 - accuracy: 0.9901 - val_loss: 5.5793 - val_accuracy: 0.5238\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 440s 22s/step - loss: 0.0844 - accuracy: 0.9862 - val_loss: 16.9033 - val_accuracy: 0.5238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0vprjMS2aYh",
        "outputId": "dc309307-a902-4bdc-fd2f-5eb1fb233633"
      },
      "source": [
        "# save model and architecture to single file\n",
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/dataFiles/DNA_Genome_Analysis_covid19/covid19vsHiv.h5\")\n",
        "print(\"Saved model to disk!!!!!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk!!!!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkfArrb7XXIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f93219-0a6a-4a44-fcf6-f3277f36c7b9"
      },
      "source": [
        "\n",
        "# load the model from the disk\n",
        "\n",
        "covidnet  = load_model('/content/drive/MyDrive/Colab Notebooks/dataFiles/DNA_Genome_Analysis_covid19/covid19vsHiv.h5')\n",
        "covidnet.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 128, 64)      1664      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 64)      102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              67109888  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 68,913,218\n",
            "Trainable params: 68,912,322\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl79D3A0Slgk"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn_NDrC3_msA",
        "outputId": "19d32b0f-caa5-4e5a-b5ef-5e9fe583150d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = covidnet.predict_classes(X_test , verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 30s 4s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75bbZd5nTGAO",
        "outputId": "f88f5daa-aaed-4d2e-abc6-cb16b1ad4b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classes = [\"Positive\" , \"Negative\"]\n",
        "print(y_test[0])\n",
        "print(classes[y_pred[0]])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0.]\n",
            "Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANTVsehuSzSi"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5O36NCUTCZf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}